{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 19:26:17.039879: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Specific Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import (\n",
    "    VGG19, \n",
    "    preprocess_input, \n",
    "    decode_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4,59</td>\n",
       "      <td>71</td>\n",
       "      <td>89</td>\n",
       "      <td>118</td>\n",
       "      <td>139</td>\n",
       "      <td>160</td>\n",
       "      <td>183</td>\n",
       "      <td>222</td>\n",
       "      <td>212</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0,Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0,144</td>\n",
       "      <td>149</td>\n",
       "      <td>129</td>\n",
       "      <td>114</td>\n",
       "      <td>119</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>135</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>115</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>113</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>88,Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4,90</td>\n",
       "      <td>97</td>\n",
       "      <td>105</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>91</td>\n",
       "      <td>44</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>83</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>32,Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,69</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>131</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>163</td>\n",
       "      <td>169</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>189</td>\n",
       "      <td>192</td>\n",
       "      <td>195</td>\n",
       "      <td>201</td>\n",
       "      <td>208</td>\n",
       "      <td>215,Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0,134</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>142</td>\n",
       "      <td>122</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>173</td>\n",
       "      <td>180</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5,Angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0     1     2     3     4     5     6     7     8     9     ...  2294  \\\n",
       "0   4,59    71    89   118   139   160   183   222   212   148  ...     0   \n",
       "1  0,144   149   129   114   119   124   125   135   145   141  ...   122   \n",
       "2   4,90    97   105    42    41    41    37    40    36    55  ...    91   \n",
       "3   1,69    72    80    87    95   102   112   123   131   137  ...   163   \n",
       "4  0,134   135   136   137   142   122    46    47    36    25  ...   171   \n",
       "\n",
       "   2295  2296  2297  2298  2299  2300  2301  2302         2303  \n",
       "0     0     0     0     0     0     0     0     1        0,Sad  \n",
       "1   115   115   128   113    64    73    77    81     88,Angry  \n",
       "2    44    42    48    83   107   105    77    51       32,Sad  \n",
       "3   169   178   186   189   192   195   201   208  215,Disgust  \n",
       "4   173   180   109     1     4     5     6     5      5,Angry  \n",
       "\n",
       "[5 rows x 2304 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv(\"resources/metadata.csv\", header=None, delimiter=\" \")\n",
    "metadata_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "emotions = metadata_df[2303].str.split(\",\", expand = True)\n",
    "labels = metadata_df[0].str.split(\",\", expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>89</td>\n",
       "      <td>118</td>\n",
       "      <td>139</td>\n",
       "      <td>160</td>\n",
       "      <td>183</td>\n",
       "      <td>222</td>\n",
       "      <td>212</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>149</td>\n",
       "      <td>129</td>\n",
       "      <td>114</td>\n",
       "      <td>119</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>135</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>113</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>105</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>83</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>131</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>189</td>\n",
       "      <td>192</td>\n",
       "      <td>195</td>\n",
       "      <td>201</td>\n",
       "      <td>208</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>142</td>\n",
       "      <td>122</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2296  2297  2298  \\\n",
       "0   59   71   89  118  139  160  183  222  212  148  ...     0     0     0   \n",
       "1  144  149  129  114  119  124  125  135  145  141  ...   115   128   113   \n",
       "2   90   97  105   42   41   41   37   40   36   55  ...    42    48    83   \n",
       "3   69   72   80   87   95  102  112  123  131  137  ...   178   186   189   \n",
       "4  134  135  136  137  142  122   46   47   36   25  ...   180   109     1   \n",
       "\n",
       "   2299  2300  2301  2302  2303  Labels  Emotions  \n",
       "0     0     0     0     1     0       4       Sad  \n",
       "1    64    73    77    81    88       0     Angry  \n",
       "2   107   105    77    51    32       4       Sad  \n",
       "3   192   195   201   208   215       1   Disgust  \n",
       "4     4     5     6     5     5       0     Angry  \n",
       "\n",
       "[5 rows x 2306 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a copy of our metadata dataframe\n",
    "data_cleaned = metadata_df.copy()\n",
    "\n",
    "# Drop the now extraneous columns\n",
    "data_cleaned.drop(data_cleaned.columns[[0, 2303]], axis=1, inplace=True)\n",
    "\n",
    "# Insert the split columns into their appropriate locations\n",
    "data_cleaned.insert(loc = 0, column = 0, value = labels[1])\n",
    "data_cleaned.insert(loc = 2303, column = 2303, value = emotions[0])\n",
    "data_cleaned.insert(loc = 2304, column = 'Labels', value = labels[0])\n",
    "data_cleaned.insert(loc = 2305, column = 'Emotions', value = emotions[1])\n",
    "\n",
    "# Convert the new columns to int\n",
    "data_cleaned = data_cleaned.astype({0:'int', 2303:'int'})\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            int64\n",
       "1            int64\n",
       "2            int64\n",
       "3            int64\n",
       "4            int64\n",
       "             ...  \n",
       "2301         int64\n",
       "2302         int64\n",
       "2303         int64\n",
       "Labels      object\n",
       "Emotions    object\n",
       "Length: 2306, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check and confirm our dtypes\n",
    "data_cleaned.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned dataframe to .csv\n",
    "data_cleaned.to_csv('resources/data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "      <th>Labels</th>\n",
       "      <th>Emotions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>89</td>\n",
       "      <td>118</td>\n",
       "      <td>139</td>\n",
       "      <td>160</td>\n",
       "      <td>183</td>\n",
       "      <td>222</td>\n",
       "      <td>212</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144</td>\n",
       "      <td>149</td>\n",
       "      <td>129</td>\n",
       "      <td>114</td>\n",
       "      <td>119</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>135</td>\n",
       "      <td>145</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>115</td>\n",
       "      <td>128</td>\n",
       "      <td>113</td>\n",
       "      <td>64</td>\n",
       "      <td>73</td>\n",
       "      <td>77</td>\n",
       "      <td>81</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90</td>\n",
       "      <td>97</td>\n",
       "      <td>105</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>37</td>\n",
       "      <td>40</td>\n",
       "      <td>36</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>42</td>\n",
       "      <td>48</td>\n",
       "      <td>83</td>\n",
       "      <td>107</td>\n",
       "      <td>105</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69</td>\n",
       "      <td>72</td>\n",
       "      <td>80</td>\n",
       "      <td>87</td>\n",
       "      <td>95</td>\n",
       "      <td>102</td>\n",
       "      <td>112</td>\n",
       "      <td>123</td>\n",
       "      <td>131</td>\n",
       "      <td>137</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>186</td>\n",
       "      <td>189</td>\n",
       "      <td>192</td>\n",
       "      <td>195</td>\n",
       "      <td>201</td>\n",
       "      <td>208</td>\n",
       "      <td>215</td>\n",
       "      <td>1</td>\n",
       "      <td>Disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>142</td>\n",
       "      <td>122</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>180</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Angry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2306 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9  ...  2296  2297  2298  \\\n",
       "0   59   71   89  118  139  160  183  222  212  148  ...     0     0     0   \n",
       "1  144  149  129  114  119  124  125  135  145  141  ...   115   128   113   \n",
       "2   90   97  105   42   41   41   37   40   36   55  ...    42    48    83   \n",
       "3   69   72   80   87   95  102  112  123  131  137  ...   178   186   189   \n",
       "4  134  135  136  137  142  122   46   47   36   25  ...   180   109     1   \n",
       "\n",
       "   2299  2300  2301  2302  2303  Labels  Emotions  \n",
       "0     0     0     0     1     0       4       Sad  \n",
       "1    64    73    77    81    88       0     Angry  \n",
       "2   107   105    77    51    32       4       Sad  \n",
       "3   192   195   201   208   215       1   Disgust  \n",
       "4     4     5     6     5     5       0     Angry  \n",
       "\n",
       "[5 rows x 2306 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = pd.read_csv(\"resources/mid_sample_data.csv\", header=0, delimiter=\",\")\n",
    "data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape: (299, 2304)\n",
      "Image Labels Shape: (299,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "X = data_cleaned.drop(['Labels', 'Emotions'],1).values\n",
    "y = data_cleaned['Labels'].values\n",
    "\n",
    "# Verify the shape of our features (X) dataset and labels (y) datasets, ensuring the images are flattened (48 x 48 = 2304)\n",
    "print(\"Image Data Shape:\", X.shape)\n",
    "print(\"Image Labels Shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGeCAYAAAA9hL66AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA69ElEQVR4nO3dbZBe5Xkn+P8553nvfrqlllC3GgkQQcZDZDFYOKwSx1KMpV3ioXDYrcoGj4u8VRkLWFR8wJHZKndSFQmoLRXOyCYh8RK2UkT+EON4amIi1dhIzmqYEhgGjRiT2COgsdS03vr9eT3n3g+sGjXq+3+p1dLcLfT/VfUH+u5zzn3uc57neh50XeeKnHMOIiIiAcShJyAiIlcuBSEREQlGQUhERIJREBIRkWAUhEREJBgFIRERCUZBSEREglEQEhGRYBSEREQkmFzoCXxYlmU4evQoqtUqoigKPR0REZkj5xzGx8fR39+PODa+67hL5Jvf/Ka77rrrXLFYdJ/85Cfd/v37z2u7wcFBB0A/+tGPfvRzmf8MDg6a7/mX5JvQd77zHWzduhXf+ta38Gu/9mv4i7/4C9xxxx144403cM0119Btq9UqAKB/5x8hLhdn/Zsodv4dGF+eIpBtASS5jI63T5a8Y9f9+xbd1hnf7PLjDe9YPFqj20Ytfmy0U/+8Gk2+rfF4wajawTcvFPzb1ur82An/FOXyef++m/y82LwAIOvyX2sASEv+Y8eNNj92zjgvct5Ryu9RF/P7rNXlnzcA1Hv8bwv1xXzf4zfw8670TnnHrus5RbddVPBvCwCFyH+PH6t10W3/+3tL6XiU8DVvvVfxjlXeTei2Of/LHgAw1ed//aVl/trMj/D7rHU9f1/5n2/8b96x481O/34nm/gPX3hu+v2cuSRBaOfOnfiDP/gD/OEf/iEA4Mknn8Q//uM/4qmnnsKOHTvotmf+F1xcLiIuz/4mMK8gFPGLFhtBKJ7yvzHlcvxms4JQLvGPx8aLIEqNr7wxCULWvwxaQSie/cPC9OYJCULsWgKA8VXeJSQIGW/GbF4AkCU8CEU5EoTSSxiEovkFIRa4ASAp+N8WkiLfd1zm551U/PdhvoNfj3yB77tA7vGccY/GFX6trddf6nmvAoCkyN8XEuslUPL/gSNjAJCU+H2WVvj2hU7/vZJv8OsF4Lz+SeWiJyY0m0288sor2Lx584zfb968GQcOHDjn7xuNBsbGxmb8iIjIleGiB6ETJ04gTVP09vbO+H1vby+GhobO+fsdO3agu7t7+mflypUXe0oiIrJAXbIU7Q9/DXPOzfrVbNu2bRgdHZ3+GRwcvFRTEhGRBeai/5vQ0qVLkSTJOd96hoeHz/l2BADFYhHFIv//tSIi8tF00YNQoVDAunXrsHfvXvzWb/3W9O/37t2Lu+6667z3k+QzxAXPPwaS5ALrn8GimP8DY7HI//Ezq/uzYOKG/x9GASCZ4GkwUUr+kdBqgJsYSREF8o/RbX7O1rgbn6DjUezPTHIl/o+bViZYRLL+rDWBkUgST/LrxcZd3rgextyykv+l6UgCCwBkxj+Et41/rG52+vdfX2ok9lR5lubV3aPesUqOZzO2M35eRZqYYCRzOL6mjTHjg3Levy7Nbr5mzcV81+0O8n5nvC1YSUdZ07gPyQ5yJEHGGckzM/Zz3n85Bw8//DC+9KUv4dZbb8X69evx9NNP45133sF99913KQ4nIiKXqUsShH77t38bJ0+exJ/8yZ/g2LFjWLNmDf7hH/4B11577aU4nIiIXKYu2WN7tmzZgi1btlyq3YuIyEeAHmAqIiLBKAiJiEgwCkIiIhLMgmvlcEa+2PI+c4k9/816VJH17LhCjqcjT5FUTOuhlTQFG0C72//8qbhpPO/rFE+TRp5c6m7jIYOj43w85anpmPI/JDGqlOmmjs0b4GnWLSP13Bpnae0W40Zsd/OU31bVf96tCv/sONVrpGAbl7txlT+9NrqKp61fs4w/hLSc86dwtzM+79h47b5X95+Yte9C0Xj4MB0F0rr/erU7+bGThvE8vqZ/PCsbqdDWszJH+eurlpLnI5I0bDZ2zt+e91+KiIhcZApCIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhKMgpCIiASzYOuEcrkMSW72+pPEen75PJTyRu0IO7RRG+KM8foyf+2ItW25yC8lq2GKa7xGwqojou0UAFqP4xLjc5AxnhVIy4MO3iYC8fyuV6vLX0PR6uSPyG918POq9/iP3VxEN0W9j9/D5aVTdLyn5G+pYNXRWQqJf/uxpr9ODgBaRiuHVuofzyf8Hl3WxevsBo/zfgtJ0b//eDlvUZEe9beHAYDKkP9eaSzm91FqdKCwapQmU/9rqJz43zdSs7LqA/omJCIiwSgIiYhIMApCIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhLMgq0TyicpEk9uPyvvsPoFWUpGHUTh9IXHbefpj3RGmvefWLvMjxs5XhOT1P01LS4yevrkjCZNBkemntR535GkycezhMzNrAOiw2hX+PVqkj4xtWVGPyFeEoOMXM5mD695seqArJoYVlPDanEAoN7mbymD44u8Y0WjliczLlhnwd/ryNrWUqnwPkrjJzu8Y86o1cm6+XuOe89/M+TH+HllxrFbnfz1NdX2H7uaI+utfkIiInI5UBASEZFgFIRERCQYBSEREQlGQUhERIJREBIRkWAUhEREJJgFWydUSNIL6icUG3VC1njOyG8vjJNBx/dt9s4h/WtYrQ0ANKq8fgOkJZDVcyQtGTUvvMwIIJtb5xUZ7WsSUr6RmzKudZ2P15fwyTUWkW2v5j2akiofT6f8L82kwhel1eQv62Onu+j4Vd3+OqKGUQdUb/Fx1o/Iem1a+661/LVwnUVe53NVmddOjZf4i2Q86/SOuYy/fqIJfl4RKZ+yynFyNT4etfg93s7846z2ai51WfomJCIiwSgIiYhIMApCIiISjIKQiIgEoyAkIiLBKAiJiEgwCzZFOxdnyMWz5x+yVM7Es835bAvYrSDYI/jjmpF228Wf38/Slc1UZv4UfLp9u8zTKZs8oxftKl+ztOQfz0r8ekUtI701JWntidHWwxjOTfA/aC3yL3pUNtoStI0LSlJcreRXq+1AjbT1AIChU/4LniTn/4j+2fhe0wBQa/J5lQv89VUlrRxKiZHrb7iqPEnHhzv8a9Ye5+dVMNox5Or+sZa/gwQAu/yieNrYnqVokzuRjX2YvgmJiEgwCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEoyCkIiIBLNg64SSOPPW/LBaH6sVg1UH1FUgSfkAmovI9ik/ttXKoU1aJsTzK3Owi0vmsW1ugv9BljcKcghnbMvGoyaflysYNWFX83qb+FTBPzbOCzTai/gF7bhqyju2qMKfz89qcQDg2sW8OORUreIds65k3jh2PvHXT5VzvA6omfJ2JSkphhtv8etRr/GCG+vlE7P6KaOtQWzVwrXJPW61TLDKuozN22RNq6SAqWlcy7Ppm5CIiASjICQiIsEoCImISDAKQiIiEoyCkIiIBKMgJCIiwSgIiYhIMAu2TohhtUBWPyFLITb6wLDaEqMOqFXlfUVYEUbS4BUambHriKTtF8b4tlYxQbObb52xuyxvXC/SLwgA4jKptzF6rbgJY9EMbknTO9Zu8JoWGPVqkyNl71ht0l+fBADlDv+8ACAzaktYndFkkx+7bhQSJbH/D6YSfj068/y8lpT8PX9GGv71BIBTDX9tFAC0SV8dAOjq8NfMTOX4e0pjskrHK+/5r1fxpPG+wC8XXGy8vsh9midNzDKrwdnZxzjvvxQREbnIFIRERCQYBSEREQlGQUhERIJREBIRkWAUhEREJJgFm6KdizPzkfS+7eYjb6Vod/jH064S37nj6ZSsC4WVgp0WjGeyk0M74y5IeXYrT1sHb0ORTfCDWy0sspo/FdoV+L0QN4zPYA2e3+pIunHcNtpbVPl9lq/420gsqvJWDh0FnspsvUZicrOMZbwlAkvBBoBW23+90oyvWYG0gQCAk3V/Tv6EkVputcdIjRRt2l7GmvfVPJ0/+3mnd6zzON93rYfPe6qPDqPW8r/x/Ief/7J3LJ3iLXHOpm9CIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEs2DohJjIegz8fqfGY++Iif/67i41aghaftyPlApFRL8PqgAAgJeUdLmc82n+K7ztL+PbtCpncIl7TUuz018sAQJvUnTij7qRVtwqkjNorcrldk98LUdF41D25D0cneOHWRMJreTrLfE17yv4L3mjxNUsSXoPUVfIfe7zO5+2M12ZCCu0qedLLBLzO52KMM/09vJfKyQ5/nVCU8eOmJb5mtav5G8vIlP9eaw/667KyutHK5Cxz/ia0f/9+3Hnnnejv70cURfje9743Y9w5h4GBAfT396NcLmPjxo04fPjwXA8jIiJXgDkHocnJSdx8883YtWvXrONPPPEEdu7ciV27duHgwYPo6+vDpk2bMD4+Pu/JiojIR8uc/3fcHXfcgTvuuGPWMeccnnzySTz66KO4++67AQDPPvssent78dxzz+HLX/7y/GYrIiIfKRc1MeHIkSMYGhrC5s2bp39XLBaxYcMGHDhwYNZtGo0GxsbGZvyIiMiV4aIGoaGhIQBAb2/vjN/39vZOj33Yjh070N3dPf2zcuXKizklERFZwC5JinYUzczIcM6d87sztm3bhtHR0emfwcHBSzElERFZgC5qinZf3/vPBR8aGsLy5cunfz88PHzOt6MzisUiikWemikiIh9NFzUIrVq1Cn19fdi7dy9uueUWAECz2cS+ffvw+OOPz2lfmYuQeeoCWFlK2+j7UUp4vUA74/nta/uPesd+sWI13bZyjNdnGGUQFOtFBACsjCE1ehVZrF5HScN/Yu4U7/My1TK+rJM1y5V5DURi9BtKG0atwzxqQ9wkf+mlVdKryOhLZdU/1Y/66zsA4Hi1yzvWtZgXjVVJHRDAexnduHSY7ztn1DcVJr1jJ5r+WhsAGG/xD8K+96Izptr++zhO+PXK2E0MYPJaf01ZYlzrdoUOA8ZrYHLYf6+wskg3h//HNucgNDExgZ/97GfT/33kyBG89tpr6OnpwTXXXIOtW7di+/btWL16NVavXo3t27ejUqngnnvumeuhRETkI27OQejll1/Gb/zGb0z/98MPPwwAuPfee/HXf/3XeOSRR1Cr1bBlyxacPn0at912G/bs2YNqtXrxZi0iIh8Jcw5CGzduhCP/OyCKIgwMDGBgYGA+8xIRkSuAHmAqIiLBKAiJiEgwCkIiIhLMZdnKgSnE/BH5LEUUANpGbuGy4oR37F+W8W07Bo086ksoIdmtrM3D+SgYT1pql/0pqHHLaLeQGqnMnf41bbd4+ndcNz6DdfN0/oS1YzjJ89bz48axj/nPOysYLUFW+duNAEBa5PdhvuRPbc8l/PV1aoLnBDfq/nUZKvDkJauVQwdpUXHzMn9pBQCUEp7O3zRKNwpkXWptfi+0Ur5v10Guh3EPtzr5mkU5fi+wJXdNUnoRn3/5gr4JiYhIMApCIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhKMgpCIiATzkasTsh6LnjN6HvzkFyvoeGPMX1TTaT02PTZy9llqvZF274yuA0zppNHSoMjnbR07VyPbGh+D4qZRB9H2zy3L80UrHef7zv8zL6AaWdf0jhUn+b5z/q4D729/2j93q3XGSJXPu9DH2zGUiv76qNE3e+i2Pf/VqOWZx8deq9VJu+Jv1/BPK/m8F910ko4vr/JiuCap9bHqgIpGjRLIa4DV/wFAi7QEAQDXnMcbB7uWc7jO+iYkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEsxlWScU04IazszJ/6m/1gAArn7dX1MzcgPfdavzwpc7LfAiCdazB7DrcZj81IWvNwA0SU+T2tL51SBVjvq3z4/zbSeu5eOWys/9/Yoy3soIpZN8TauD/hokl+MXs3PI6NFUNnr+LPJvv5i3KkLHMd6DCZF/3y2jiGjkBn4zsBLART+lm2Jicikd/9kn+AXt7fbfbJlR4GTVNiZV/5q6mL+nWDVl+eN8+8ox/9wmV/jv4cjq1XUWfRMSEZFgFIRERCQYBSEREQlGQUhERIJREBIRkWAUhEREJBgFIRERCWbB1gllLvLm16fZhcfO1GpKYuh6/YR3LG4vodvGbaspEBkyrpRVB8TqVtrGmiRNPu80z7evXeUfT8t8393/QodRmPQXh7RLfF6L3uTHnurli1oY9W9v1W2VRnkPp9ykv54tcnzeUWrdZ8Y42T6r8MKT+lJeT9Po9tf6TPbzNZtakdJxJsvzGqMcb7GEyWMddPxE4r+ehRyvTUxifi9UO/zFWbWreM1XWuXHzg3zdYlb/nuhMEpe143zf5/VNyEREQlGQUhERIJREBIRkWAUhEREJBgFIRERCUZBSEREglmwKdppFiPypGL7H3IP5IzHojczfsqNpTwNNOsoeccqb0/SbWE8gj9pkvRX8gh8ACiM87Rblh7ujH1brRzSbr59+bh/++LPjPTUt3jubFr0p5hmBZ5+mjT4tc7XeLoxW7d0iq+JldbervrvhchK9TeyY+MmX/P8e2PeseT4CN/2F3zNO4v+Ne3Jz+/tqLay6h07+ct8XlbrjdhoTTA1WfSO5bv4fdZMjfRxkv49uoJfy6tWnqbjK24aoeOHf+zvT5PU/NvNpXWMvgmJiEgwCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEoyCkIiIBLNg64QaaQ7t9uzTKyT+vHtntCWot/mj6AtL/I9NB4B6n//R6aXjJHEegEv43CJS/hEZT7EvjfA/KIy0vGNxi2+blvltUhgxWkGQepzciQm6bVRv0PG4o+wdc0ZdltXyIE9qkACgsdi/LrGx79oS4/Nf5N93YdyoZcvx6xE3+bFzY/6imXQRbx1w8hOddLz7iL/Kr/gevxcmVnfT8fGr/WuW+st4AACNpbzeJuvka97Z4b9PF1f4+0LLqBNKM3I9E6MdSYMXQN12zVt0/LUVK71j8RF/zaTjHSRm7uf8/1REROTiUhASEZFgFIRERCQYBSEREQlGQUhERIJREBIRkWAUhEREJJgFWyfUTmO4dPYYyWqBUlJDBAAjDX9dCQCsWDJCx0+tWuEdK4ywTkdAWuHLHZFShSjj9QBJg9c50O2tfdd40n9c89cgAUB8YtQ75sZ5bYjROQfu1Ij/uF3+/jIAANLbBgAS416ZuNpffNLm5TRoLuJn1jzp/3zYcZTvm91HAFA06sIavR3esZFf4nV2Y7/Ez6vV5V+zuMGLeUbW8vuw5+oT3rEOs8cSP6845ou6vDruHSvm+LzHMn+9DcDf71wH33e1zOsefzrZR8eXLvWf1+m8f02yKX7cs+mbkIiIBKMgJCIiwSgIiYhIMApCIiISjIKQiIgEoyAkIiLBLNgU7UYrh6Q1+/SShKQGGjm9beOx6Usqk3R89CZ/emvPT43lNOaWNP3nlRb45wUX8xzUdtl/3vmUp5/mBv2prwDgmjxFO+td4h2LM37s9MQpOs64yMjLrSw1dsAv2OTV/vH4On4fFfI8TXripD/Hu9nN77PiaX7etaX8XkqaVmK8X/k9vu+MTL22zHqB8HGWytxZ4inDBSONupLn93h30d+uoZny69XOLvy7QLGDl4VYjoz5X5sAcE3Xae/Ydd3+12Zrsom3znMO+iYkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEsyCrRNqNnKIk9kfr57LkRoL/nR+JBGvNRht8MeqV/r9rQfqS3nrgMqxBh2Pm/7PBFmO136kJT5eGPGfdzJmPHY9z2+TdCWvt5m4xl/zUjzlbxsAALmpXn7s0oXfwnGL1yi1qkZ9x1X+2pFblh+j25YSXpfyX2P/I/brnfwmrx/hfSQW/TMdRtwirxGj9MqqzWp3km2Nj8RRgddWJbF/3qyGCLDrgMo5Pl6I/XM73eDXo+aphzyjVPAfOzPOy6qLLBqtb4Ymu7xjXUX/+0abL9cMc/omtGPHDnzqU59CtVrFsmXL8IUvfAFvvvnmjL9xzmFgYAD9/f0ol8vYuHEjDh8+PJfDiIjIFWJOQWjfvn24//778dJLL2Hv3r1ot9vYvHkzJic/qA5/4oknsHPnTuzatQsHDx5EX18fNm3ahPFxf3MkERG5Ms3p/2W88MILM/77mWeewbJly/DKK6/gM5/5DJxzePLJJ/Hoo4/i7rvvBgA8++yz6O3txXPPPYcvf/nLF2/mIiJy2ZtXYsLo6Pttm3t6egAAR44cwdDQEDZv3jz9N8ViERs2bMCBAwdm3Uej0cDY2NiMHxERuTJccBByzuHhhx/Gpz/9aaxZswYAMDQ0BADo7Z35j8m9vb3TYx+2Y8cOdHd3T/+sXLnyQqckIiKXmQsOQg888ABef/11/O3f/u05Y9GHMmScc+f87oxt27ZhdHR0+mdwcPBCpyQiIpeZC8pvffDBB/H9738f+/fvx4oVK6Z/39f3flrp0NAQli9fPv374eHhc74dnVEsFlEsFi9kGiIicpmbUxByzuHBBx/E888/jxdffBGrVq2aMb5q1Sr09fVh7969uOWWWwAAzWYT+/btw+OPPz6niaXNBC6ZPcfdZf7c+IyMAUDBqDXIGnz7atmfGz++sptuWzppfPG88DYuqC3m9QBMo2cxHad1IwAio4lT0vDX47Q7+LytWp247T+2NS9n1F5NXcWPnS9PeccqRl1JV57XZvVW/fVoxzJ/7QYAJDeN0PFTRX6fdr7lv0+NMjs0eakcmov9O2h3GXVAeV7XxS53EvNtuwv+fkAAEBsnfrzmL4AaHifFUbBrfVj9kzWvyBjPG3VCrNdRKfHf4y2jDu5scwpC999/P5577jn8/d//ParV6vS/83R3d6NcLiOKImzduhXbt2/H6tWrsXr1amzfvh2VSgX33HPPXA4lIiJXgDkFoaeeegoAsHHjxhm/f+aZZ/C7v/u7AIBHHnkEtVoNW7ZswenTp3Hbbbdhz549qFaNj0giInLFmfP/jrNEUYSBgQEMDAxc6JxEROQKoQeYiohIMApCIiISjIKQiIgEoyAkIiLBLNh+QmjFQG72GMkz/rmmMZ6fvYXReZlcwWe26Ge8JqZd8n8mYPUwAFBfzD9PZAX/sYuk1xAAZEYJUmIsqlVnRI9t9IfK8v4ai7Qwv89Y1rFbE/4/OGX0kCmTGgsAWFKa9I6N1Mp0284i71t19SdH6fjPV/j7QzXJOQMAjDo91hOoUOK1JZ0VXlvVU/HX+lj9gMabvI/YZIuf98iU/5rU6/xNpVDg591q+1+AqVFjFBvXoyPHX7zsPqzm/PdZs2W9035A34RERCQYBSEREQlGQUhERIJREBIRkWAUhEREJBgFIRERCWbBpmhHzRhRMnuMZI+wsx6L7umtN40ncgJTDZKquZSnxja6eRqoMXXKfMR+t3/nkfHU9eI4H29VjDRR8rR4K/3b2nebjDvjI1bpNF+0lKR/A6C1Ai3jxMpGXnst9af1dhT4ttbj/a259XT503KnivwVkpJH/wNAs+k/dpLwEofYuBwTTZIyT1KoAWCyxnuaNY00a1cja2rch22jzUS56B9PU34t600jPdxouXB1acQ71sj8+47Yi/5D9E1IRESCURASEZFgFIRERCQYBSEREQlGQUhERIJREBIRkWAUhEREJJiFWyfUihAlvsIAf+x0Ec+5T8Hz6p3xpPo6KQUqVXj9Rn0xr1XoGPLPvd7DiySShlEb0unfvmHs21hSc5w9Bd+qxTFbOZDxhD/5324xYRWVkcfk11q8PmOyzetSuvL+yXcV+YmNN/m+LQmpM6qWeC3cJKujA5Dl/GvWbPK3o4ZRq0OPW+P7jmrG53Grhi9H7iWj/ikzan2S2L9v54z3u5Sf12mj5Qhr9XCy0eEda9XUykFERC4DCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEoyCkIiIBLNg64TidoS4PXtyvtF1hI5aefWZ4zn7bVIOkMvxHhr1q3hdStz2z73NS4xQfdeoFyj4Cx3a/nR/AMBU3zwaHQGIScuS2GjgZNUJgSxpZLQ0sXowWf2IkPh30Gjzl9Zkyk+sSuqECmxBATjH+1ZNGXNj/Yisfl2x0Runo+SvH4lJPQwA1I06oYy8fqyLHXnea85XlPq3zwp8TSJjbimpR2sb/ZusUjdr+/3/coN3LBv3X4+sZhTpnUXfhEREJBgFIRERCUZBSEREglEQEhGRYBSEREQkGAUhEREJZsGmaEft939mE5Pnqjsj7TYz8m6dsQOWbNlIeApp2sfzkQtj/rTdwiifl9XKoTLsz1dudfA1aXbxPE8zlZlMzRl3oLVvmoZtpWBb6av8KffId/nbGqxefJxuu7Jymo6Pt/1p1ifrPKe+YbQGOH66SsdT0vagY3GNbpsYKdq5xH/BCjmeeg6eeY5mwz/vFkvfBuDyxuvLaPWQlv3nnZT5eRWK/H2hSVLqM5K+DQDNBn9PGssbbT9OkvFOcl6p0d/lLPomJCIiwSgIiYhIMApCIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhLMwq0TakWIk9lz4FktjzPy5i1Wdrsjz0Zn9RUAkFR4vUCa99cJWS0Pmp3880THMf8j9POTfNvCBB+vd1s1FORR9FarBgPrvBFlxuP759nKod288JfPZJvXZ5xo+GuBllfG6LZts3CLO/n2Mu9YfcRoA9HP64jKZf99aLWJaBu1PhlpSxAl/JXtSsaxSdsOAABp10BbTABogtfylCv+ejSQmknAriNiawYAWOo/dkJab0Qwar7Oom9CIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEs2DqhuO2vjXGknsClRj6/kVdvYf2IrF5Eacz7vNRW+HPrO47xbfM1ow7CU3MFAEnj/Ht/zKYY8zWtsVogozbE6vkTk35COV6ygka3URtS4dfTTflfPu9OLOL7Nno4XUqJUSDV6vYvaucR/pbRaPAmTOMr/PdxocSL4fJ51jwKSEgtUJoa613mx07b/PWXtsj7AhkDgLYxzm7jyOjfFJNaHgBoGucVke1L5HqlmeqERETkMqAgJCIiwSgIiYhIMApCIiISjIKQiIgEoyAkIiLBKAiJiEgwC7ZOKErf//GN+TijZiWySmLMhkJkU6OmxYHn5KPkP7GT/5rvfPFh/nkiaZDeH46ftLVmSZP/QW7Kf94Zb6Vi9vxhfZbyNb5xrs73nRb5mrqc/7wGc0votrU+fuKTdX9xVf0XnXTb8pDRd4e3MkK01H8fTl7Da3U63jHqTpz/4I0+Pu98zxQ/dsnfq4jVFgJALuHnNdXgja+mpvznZfVBQvvCewKVinzeLaMPWduoE8rl/Psv5kmdEBn7MH0TEhGRYBSEREQkGAUhEREJRkFIRESCURASEZFgFIRERCSYBZuiHbeA2BciSUYj6bTw/riZoj2/Vg9010a6sXP+dEnXwVMxT32Kj+df9F/q0kmr/YXBSqMm7TVYijUARMb1KIySgxutNTrf5Tna1bf59qdu6vCOTdD+FcDJyR463jHov5Gvf5nPOzfaoOMn1nXR8TpJw168dJxuO7akTMfz/+xv9ZA7ydPW62W+pnmSZt1d5mvWSo1UZSOFu1T2p4dPGinaznjTYi0qWi0+7yzj+46NGog8SQFn+7aOO2MO5/2XAJ566imsXbsWXV1d6Orqwvr16/GDH/xgetw5h4GBAfT396NcLmPjxo04fPjwXA4hIiJXkDkFoRUrVuCxxx7Dyy+/jJdffhmf/exncdddd00HmieeeAI7d+7Erl27cPDgQfT19WHTpk0YH+efnkRE5Mo0pyB055134jd/8zfxsY99DB/72Mfwp3/6p+js7MRLL70E5xyefPJJPProo7j77ruxZs0aPPvss5iamsJzzz13qeYvIiKXsQtOTEjTFLt378bk5CTWr1+PI0eOYGhoCJs3b57+m2KxiA0bNuDAgQPe/TQaDYyNjc34ERGRK8Ocg9ChQ4fQ2dmJYrGI++67D88//zxuuukmDA0NAQB6e3tn/H1vb+/02Gx27NiB7u7u6Z+VK1fOdUoiInKZmnMQuvHGG/Haa6/hpZdewle+8hXce++9eOONN6bHo2hmNpNz7pzfnW3btm0YHR2d/hkcHJzrlERE5DI15xTtQqGAG264AQBw66234uDBg/jGN76Br371qwCAoaEhLF++fPrvh4eHz/l2dLZisYhi0Xisr4iIfCTNu07IOYdGo4FVq1ahr68Pe/fuxS233AIAaDab2LdvHx5//PE57zdpwNv4gKbVG9/tMqObgtnqgXyrM79XGiVIGXncvFHyAhT4xBvd/smVTvMaiHZpfjXNWcIKu/i2rAUFAOTq/vOuLeHzTgu8pqXn4HE6vuR1/7E7jvF9T/Tzl15Eisre+1SJbtvs4h/qmsvadHzRkgnvWI7UrADAtctO0fGxLn87htNv8tqp7AQ/rxap1bHqgKyXl9UKgrVbSHJ8zaxWD21SC5TL89euS/m8SWkiAN6uga1paqzX2eYUhL72ta/hjjvuwMqVKzE+Po7du3fjxRdfxAsvvIAoirB161Zs374dq1evxurVq7F9+3ZUKhXcc889czmMiIhcIeYUhN577z186UtfwrFjx9Dd3Y21a9fihRdewKZNmwAAjzzyCGq1GrZs2YLTp0/jtttuw549e1CtVi/J5EVE5PI2pyD07W9/m45HUYSBgQEMDAzMZ04iInKF0ANMRUQkGAUhEREJRkFIRESCURASEZFgFmw/oaTlkHh6XbA6IRfz/HRjGJm1IrSXkZGTbxw7or09jJ4kCa90aJIWMta8s7wx8Xm0I0p46xvka8Z5dfrXpdEzv/OauoHXrZTf9T8dvvIOfwZiYYTX+ox8zN93p7aMr0la5bUjUYmPT9X9fXs6yvyC1dv8BdRT9tcJda7l+37n8HI6PjHU6R2LlvM1K+V57VQSX/hNbtUYxUatT9b01+O0msb3CKNOKOrk5836AtVJz6ysZhVcfkDfhEREJBgFIRERCUZBSEREglEQEhGRYBSEREQkGAUhEREJZsGmaMctO516Ns5IpbQeXW71W8hIRqOVbkxbUMBKlTbOy0gDbVUvPMU0bhkpwQUjDZRla1op88b1anZfeJuIiGfGot7DD54Wu/kOCJZaDgA50sIiNtJuU5rqDzijdUCW+scnpng7hfEJ3sLiBGkF0d1Zo9v23MDbRJx4Z5F3jKUTA3aKdkpaNQD89cdLL4DMemMgadhR25hXfh71EwAaLX+I+K2P/xf/dhMt/LvzPIa+CYmISDAKQiIiEoyCkIiIBKMgJCIiwSgIiYhIMApCIiISjIKQiIgEs3DrhNpA7AuRJPXdrMUxnjDujJz+mOTlZ3m+b7YtADhSj5MZBTVRk4+3O/z7blWsmhW+aM2C0WaCDBcm+L5bHUZNC1nzpEk3NWvGUqPVQ7r4wu8FWjuF9+9/n9yEURPWZRVfGfcKe1sw7uG4xheVnfbxAm9vkVvEL+jiFaPesZHTHXRbVg8DAK02P6+2UXvFWHVbccM/brWHQcxvtNRoBfG5G9/0jj3e+5p3bKySqU5IREQWPgUhEREJRkFIRESCURASEZFgFIRERCQYBSEREQlGQUhERIJZsHVCUeYQZbPXtrAaisw4I6vvjpV378j+Y6M/jTPGWX8bb83UGS2jpqXirxeoLeGL1n3EmLiB1cRY9TLW9SiM+eufrH5BZi8j3oKG9lFq9PBtkzofb5fJvpcYi1Y0xo3akGjCfz8YZXRIpvii5ti4UeTXrPHxiX7/5CpV3uxr0uiTZJXjZKTHU5TwRYtIjyUAtC7Ses/JSI0RALgcn9u/XXLAO5aSQrvUKsg8i74JiYhIMApCIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhLMgk3RdnEEF/vSHv1phSx9GwAyM13Sytsl21op2EbWYkQese+ckRtrPJ4/IimkU8v5vrvf4ocujfITZy0RWCoyYK9Zrsa2NdbMGG5XjLYFpPVG6TjfttnNj90inQdKw0Z7ixEjt9wQk44JbL0BoDDKF7U04r9XrDYs4yt4O4VJV/aOZddN8J0btQCp1YaFvP5i2sACcE1+Xglr02K8XVltPwpX83W5Me9/Qx3LWt6x8Uwp2iIichlQEBIRkWAUhEREJBgFIRERCUZBSEREglEQEhGRYBSEREQkmAVbJwQHbx1HlBoFHkQUGbUfRq1PTI6dGbU6Vl2K9Zj8+WwckTqH1mKe02+1eiif4MVZ/novwLqUhQk+t7jt30HSsNaE7zs3xc8rbvjH45q/hgIAsg7eOqCxpOQdKx6f4vOaIoU+ANo9pAgJQLM77x/r4jUtrL0FAEws929vXS/WtgMAsiH/Z+qJzgrdFnmjroXU2QEAjPpDynpfIFMj3RQAALlJPu/1V79Fx0uR/7V/KvO3x6irlYOIiFwOFIRERCQYBSEREQlGQUhERIJREBIRkWAUhEREJBgFIRERCWbB1gnFqfPWgNBaHquFjBV2rZx9cmyzn9A8Sgnm04sIABzpreOMGofxa/m+K8fpMO27kxh1DvkJvqiFUX9NTDJWp9tGdV5Pg5Qf2xX89TTIGSdm1CiB9I869Ykuuml9idHLiG+O5mL/eUeL/bUhAJDk+ZplGXkB/sLfDwgAiqf4eeVI+VTpKH+raxq1ci7HXyOu4N8+i/i9EDX5mxJ7z8qP8TVp9PDzum/Zj+h43fmv5/959H/xjjUnmgCeo/s+Q9+EREQkGAUhEREJRkFIRESCURASEZFgFIRERCQYBSEREQlGQUhERIJZsHVCcP66mojUvFh1Pla/oGwe9ThmLY9VR8Ra0FhXah69iqw6hXofn3htCa+DqBxnfXn4sVm/IABwpD9UfYVRT7PYWFSjhUy7RHo0dRr1G918342lpO6kzK9HVDb6O9WM8yb3cXSc90FqG+VRjvTtiY1anDZvg4SY9PxhNUQAkJb59cpISRgApAnZ3hk9zBpG/RPpCVQYo5vi1s+/Qcevz/F75W/GbvSOvfU1/1i7zWv0zqZvQiIiEoyCkIiIBKMgJCIiwSgIiYhIMApCIiISjIKQiIgEs2BTtKPMn/LM2ykYKb0slRLzTOG20qTN9O9Lsy0AOJZaTtoGAEBG0moBYORGfhtV3iOtHBp83+b1zPk/R6XFC39EPmCvadK48N4cVspw57v+65Wv8YmnhQIdb3Tz7TNyOZ3xjtHm3RiQkrR2S0RSsAHQ1PKUZ5ab94IzUs+j9oWfV9zk25aH/ffZ6VtZXQfwQN9/pONvtvjC/PX/9W+8Yz0//E/+DR2f19nm9U1ox44diKIIW7du/eDYzmFgYAD9/f0ol8vYuHEjDh8+PJ/DiIjIR9QFB6GDBw/i6aefxtq1a2f8/oknnsDOnTuxa9cuHDx4EH19fdi0aRPGx8fnPVkREflouaAgNDExgS9+8Yv4y7/8SyxevHj69845PPnkk3j00Udx9913Y82aNXj22WcxNTWF5547vy57IiJy5bigIHT//ffj85//PD73uc/N+P2RI0cwNDSEzZs3T/+uWCxiw4YNOHDgwKz7ajQaGBsbm/EjIiJXhjknJuzevRs/+clPcPDgwXPGhoaGAAC9vb0zft/b24u333571v3t2LEDf/zHfzzXaYiIyEfAnL4JDQ4O4qGHHsLf/M3foFQqef8u+tBDJZ1z5/zujG3btmF0dHT6Z3BwcC5TEhGRy9icvgm98sorGB4exrp166Z/l6Yp9u/fj127duHNN98E8P43ouXLl0//zfDw8Dnfjs4oFosoFo38SRER+UiaUxC6/fbbcejQoRm/+73f+z18/OMfx1e/+lVcf/316Ovrw969e3HLLbcAAJrNJvbt24fHH398ThOLMudt2RCRx/uzlgUAzFoeC63lMWpaWBsIwGi3YNVIGI/BZ/u2liRq8S/MjRW8JmD0l/x1K0sOGQUzhqjtvyD5cb5mScNoI9HihUJx3V9UFpN5AUDU4GsWtfz7dgX+smW1UwDQrvIPfY3F/r4FVo2R1cKiTVomWO0SLM1u/52c8dIpZEXj9WPUD7J2DdZ7UuUoX7PaMv/Yg//TD+m2ifHq/p3v30/Hb/i//bVASZe/VYpzTeA8/3l/TkGoWq1izZo1M37X0dGBJUuWTP9+69at2L59O1avXo3Vq1dj+/btqFQquOeee+ZyKBERuQJc9CcmPPLII6jVatiyZQtOnz6N2267DXv27EG1Wr3YhxIRkcvcvIPQiy++OOO/oyjCwMAABgYG5rtrERH5iNMDTEVEJBgFIRERCUZBSEREglEQEhGRYC7PfkKsnsZTW3T+40Y9Dju2VXBj9KehKf1WryJjfD7lUS6e385P3eIvsug8ymtWSsfr/NCJ/3NU3ODFHUm9TcfNuq8m2d7o0eQSq0GN/z606oSai/ma1pbw7etL/GvaNJJc2x1GbypSr5PlrTUzxsn2Vp1d1DJqyqYuvF9Q6ZRxbON94ROb3/SO3Vg6Srf9P9783+n4jX/6czqekQcJOHKPs7EP0zchEREJRkFIRESCURASEZFgFIRERCQYBSEREQlGQUhERIJZsCnacLigvGLyRHUAQEzaQABAWjAbG8xtQmdvOc806/lg62KtmXnKRvprUvW3LTj66/7miABw3b/nqcwuIcc25h0ZrRqsV0e7x5++2uzi8251GC0ROkjLA6MtQb2H30itxfy8XZG0mTDS9ZMyT3uPyU0eGTeiaxufmWv+NY+Mth25CX7snJGiXRzxn1d+kq9Z8389Tcc39Pyzd+z/Hf8Y3bb0xGI6nh7/73Q8Zg+ezsh95Kx6lLOOcd5/KSIicpEpCImISDAKQiIiEoyCkIiIBKMgJCIiwSgIiYhIMApCIiISzIKtE4oy5227QNsxGK0aXDy/x6pH5BHl1uPi59VP4VKab4GSUTuSNvz1G4VrJ+m2797eScdX/Mead6xd4bU6aRe//dMCv57Nqv8zHKvzAYCUl0ehXSaDxkfHjHdygCvxFhdxkY8zF15FB8Qxf/GlbX69knFyn53mi1Z5j9/DhXE+N/YSGrqzQbf93675KR2fIoVh3/u7T9NtV/7wAB2PKxU6jhapGWPc+d9D+iYkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEswCrhOya3YuyXHnUzIznyIJa9cB1uKDg89vPEr8k281+C2Y/1cTdPxow19H1P/jKbptVuCNebIcP7GYlFAUxoyePkZNGbvejpc/IW4Y+27n6Xha8l8TZ/Tbahs1Y/Rjr3GPJ5P8xEsn/efd8Qs+r+ogr+Vpd/Bjv32Xf+yOj/83um0+4jU1/8+/3OYdu+7P36TbZjnjLZ71BAKAmFwwa9vzpG9CIiISjIKQiIgEoyAkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEs2DohF7//M+sYKYOIjH5Bl7KWx+oXZNYgkXHfWpzvsS+pjC+qI+NRYtSdNI2imH/tryP6Rcx7EfX9Z14bUjR6U6VF/0Vh9ygAxG3+B9mkfzzjZT5mTZk7zsdbHf7zsvogWcz7mMjzkjGUT/hPvHOwTrdtLuY1Y+/cye+F9b/8M+9YI+Vvs2+1ltDxJU93eMfSEyfptnFpnheM7pxczDlcaH0TEhGRYBSEREQkGAUhEREJRkFIRESCURASEZFgFIRERCSYBZuizTiWhm2kKrvESCdeoGHZbOUwn9RzK594vvnfdP98386YG2sF4T7Bc3qPJTyF++r9PK03N8kfwc+0yzz13JE2ElHK1yxuG9fLSj0nc0uLRmq58fqiZQqOz6t4uk3H8xP+3hqNniLd9p1/w4+97l8doeMZeQEWEz7vH//wE3R81QsveceiPE8td8aaRpHxfphe2D3u3Pm3eVigb7kiInIlUBASEZFgFIRERCQYBSEREQlGQUhERIJREBIRkWAWXIr2mZTCdsufHhu3/GmH1pOqWSolAKTGU7jZ+Hy2fX+cjNEtgcw48YxkTGZGyq9jGwOA8SRsNh7lzj+Vc66yNk+NBUnvBoB2m6doz0e7ZaRok9R0M0XbGDdTtMncrHs4M56oPp8U7cS4nlHbn6LdJu8ZAJDV6DBak0067mL/fdxs8m2zOr/P2s5/XvaT+Y3rYW1+gdUZZ+ZspYgDQOTO56/+B3r33XexcuXK0NMQEZF5GhwcxIoVK+jfLLgglGUZjh49imq1iiiKMDY2hpUrV2JwcBBdXV2hp3dZ0JrNndZs7rRmc3elrJlzDuPj4+jv70fM+g5hAf7vuDiOZ42cXV1dH+mLdilozeZOazZ3WrO5uxLWrLu7+7z+TokJIiISjIKQiIgEs+CDULFYxNe//nUUi/wBhPIBrdncac3mTms2d1qzcy24xAQREblyLPhvQiIi8tGlICQiIsEoCImISDAKQiIiEoyCkIiIBLPgg9C3vvUtrFq1CqVSCevWrcOPf/zj0FNaMPbv348777wT/f39iKII3/ve92aMO+cwMDCA/v5+lMtlbNy4EYcPHw4z2QVgx44d+NSnPoVqtYply5bhC1/4At58880Zf6M1O9dTTz2FtWvXTlf5r1+/Hj/4wQ+mx7Vm3I4dOxBFEbZu3Tr9O63ZBxZ0EPrOd76DrVu34tFHH8Wrr76KX//1X8cdd9yBd955J/TUFoTJyUncfPPN2LVr16zjTzzxBHbu3Ildu3bh4MGD6Ovrw6ZNmzA+Pv4/eKYLw759+3D//ffjpZdewt69e9Fut7F582ZMTk5O/43W7FwrVqzAY489hpdffhkvv/wyPvvZz+Kuu+6aftPUmvkdPHgQTz/9NNauXTvj91qzs7gF7Fd+5VfcfffdN+N3H//4x90f/dEfBZrRwgXAPf/889P/nWWZ6+vrc4899tj07+r1uuvu7nZ//ud/HmCGC8/w8LAD4Pbt2+ec05rNxeLFi91f/dVfac2I8fFxt3r1ard37163YcMG99BDDznndJ992IL9JtRsNvHKK69g8+bNM36/efNmHDhwINCsLh9HjhzB0NDQjPUrFovYsGGD1u//Nzo6CgDo6ekBoDU7H2maYvfu3ZicnMT69eu1ZsT999+Pz3/+8/jc5z434/das5kW3FO0zzhx4gTSNEVvb++M3/f29mJoaCjQrC4fZ9ZotvV7++23Q0xpQXHO4eGHH8anP/1prFmzBoDWjDl06BDWr1+Per2Ozs5OPP/887jpppum3zS1ZjPt3r0bP/nJT3Dw4MFzxnSfzbRgg9AZUTSz959z7pzfiZ/Wb3YPPPAAXn/9dfzTP/3TOWNas3PdeOONeO211zAyMoK/+7u/w7333ot9+/ZNj2vNPjA4OIiHHnoIe/bsQalU8v6d1ux9C/Z/xy1duhRJkpzzrWd4ePicTxByrr6+PgDQ+s3iwQcfxPe//3386Ec/mtG7SmvmVygUcMMNN+DWW2/Fjh07cPPNN+Mb3/iG1mwWr7zyCoaHh7Fu3Trkcjnkcjns27cPf/Znf4ZcLje9Llqz9y3YIFQoFLBu3Trs3bt3xu/37t2LX/3VXw00q8vHqlWr0NfXN2P9ms0m9u3bd8Wun3MODzzwAL773e/ihz/8IVatWjVjXGt2/pxzaDQaWrNZ3H777Th06BBee+216Z9bb70VX/ziF/Haa6/h+uuv15qdLVxOhG337t0un8+7b3/72+6NN95wW7dudR0dHe6tt94KPbUFYXx83L366qvu1VdfdQDczp073auvvurefvtt55xzjz32mOvu7nbf/e533aFDh9zv/M7vuOXLl7uxsbHAMw/jK1/5iuvu7nYvvviiO3bs2PTP1NTU9N9ozc61bds2t3//fnfkyBH3+uuvu6997WsujmO3Z88e55zW7HycnR3nnNbsbAs6CDnn3De/+U137bXXukKh4D75yU9Op9OKcz/60Y8cgHN+7r33Xufc+6mgX//6111fX58rFovuM5/5jDt06FDYSQc021oBcM8888z032jNzvX7v//706/Bq666yt1+++3TAcg5rdn5+HAQ0pp9QP2EREQkmAX7b0IiIvLRpyAkIiLBKAiJiEgwCkIiIhKMgpCIiASjICQiIsEoCImISDAKQiIiEoyCkIiIBKMgJCIiwSgIiYhIMP8fQkYlMxKfgPAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Image Check: Create a copy of our data_cleaned dataframe with just the image features and convert a row to an array and resize to a 3 dimensional image in order to display via plt.show function\n",
    "image_data_df = data_cleaned.copy()\n",
    "image_data_df.drop(image_data_df.columns[[2304, 2305]], axis=1, inplace=True)\n",
    "\n",
    "arr = image_data_df.iloc[4].to_numpy()\n",
    "arr_test = np.resize(arr, (48, 48))\n",
    "plt.imshow(arr_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Info\n",
      "Training Data Shape: (224, 2304)\n",
      "Training Data Shape: (224,)\n",
      "Test Data Info\n",
      "Training Data Shape: (75, 2304)\n",
      "Training Data Shape: (75,)\n"
     ]
    }
   ],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y,\n",
    "                                                    random_state=1,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Check the shape of our split data\n",
    "print(\"Training Data Info\")\n",
    "print(\"Training Data Shape:\", X_train.shape)\n",
    "print(\"Training Data Shape:\", y_train.shape)\n",
    "\n",
    "print(\"Test Data Info\")\n",
    "print(\"Training Data Shape:\", X_test.shape)\n",
    "print(\"Training Data Shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train = np.resize(X_train[1], (48, 48, 1))\n",
    "new_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 225 is out of bounds for axis 0 with size 224",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f_/gtsdwfmx7s384m5wp2qkks000000gn/T/ipykernel_1165/3552731838.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnew_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimg_resized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m48\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnew_X_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_resized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 225 is out of bounds for axis 0 with size 224"
     ]
    }
   ],
   "source": [
    "new_X_train = []\n",
    "for i in X_train:\n",
    "    img_resized = np.resize(X_train[i], (48, 48, 1))\n",
    "    new_X_train.append(img_resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 48],\n",
       "       [ 37],\n",
       "       [100],\n",
       "       [212],\n",
       "       [208],\n",
       "       [211],\n",
       "       [210],\n",
       "       [203],\n",
       "       [191],\n",
       "       [183],\n",
       "       [191],\n",
       "       [205],\n",
       "       [209],\n",
       "       [210],\n",
       "       [211],\n",
       "       [212],\n",
       "       [210],\n",
       "       [212],\n",
       "       [214],\n",
       "       [214],\n",
       "       [208],\n",
       "       [196],\n",
       "       [186],\n",
       "       [185],\n",
       "       [183],\n",
       "       [173],\n",
       "       [166],\n",
       "       [154],\n",
       "       [136],\n",
       "       [113],\n",
       "       [ 88],\n",
       "       [ 63],\n",
       "       [ 44],\n",
       "       [ 38],\n",
       "       [ 34],\n",
       "       [ 31],\n",
       "       [ 30],\n",
       "       [ 28],\n",
       "       [ 28],\n",
       "       [ 28],\n",
       "       [ 28],\n",
       "       [ 27],\n",
       "       [ 27],\n",
       "       [ 27],\n",
       "       [ 27],\n",
       "       [ 27],\n",
       "       [ 26],\n",
       "       [ 29]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X_train[47]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling and Normalization \n",
    "**We use Sklearn's MinMaxScaler to normalize our data between 0 and 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the training data to be between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternative way to normalize this dataset since we know that the max pixel value is 255\n",
    "# X_train = X_train.astype(\"float32\")\n",
    "# X_test = X_test.astype(\"float32\")\n",
    "# X_train /= 255.0\n",
    "# X_test /= 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-Hot Encoding\n",
    "\n",
    "**We need to one-hot encode our integer labels using the `to_categorical` helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2', '4', '1', '6', '4', '1', '2', '1', '0', '6', '6', '0', '1',\n",
       "       '1', '4', '3', '0', '1', '2', '5'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our Training and Testing labels are integer encoded from 0 to 6. Look at the first 20 training labels.\n",
    "y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert our target labels (expected values) to categorical data\n",
    "face_classes = 7\n",
    "y_train = to_categorical(y_train, face_classes)\n",
    "y_test = to_categorical(y_test, face_classes)\n",
    "# Our first row label [0] of `2` is one-hot encoded as `0010000`\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building our Model\n",
    "\n",
    "**In this example, we are going to build a Deep Multi-Layer Perceptron model with 2 hidden layers.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Conv2D\n",
    "# from tensorflow.keras.layers import MaxPooling2D\n",
    "# from tensorflow.keras.layers import BatchNormalization\n",
    "# from tensorflow.keras.layers import Activation\n",
    "# from tensorflow.keras.layers import Flatten\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "# from tensorflow.keras import backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Source: https://www.kaggle.com/code/gxy19980906/320203298minivgg11\n",
    "# class MiniVGG11Net:\n",
    "#     @staticmethod\n",
    "#     def build(width, height, channel, classes, reg=0.0002):\n",
    "#         model = Sequential(name=\"MiniVGG13\")\n",
    "        \n",
    "#         shape = (height, width, channel)\n",
    "#         channel_dimension = -1\n",
    "\n",
    "#         if backend.image_data_format() == \"channels_first\":\n",
    "#             shape = (channel, height, width)\n",
    "#             channel_dimension = 1\n",
    "        \n",
    "#         model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization(axis=channel_dimension))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "#         model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization(axis=channel_dimension))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "#         model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization(axis=channel_dimension))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "        \n",
    "#         model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(BatchNormalization(axis=channel_dimension))\n",
    "#         model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#          # 第一全连接层\n",
    "#         model.add(Flatten())\n",
    "#         model.add(Dense(1024, kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         # model.add(BatchNormalization(axis=channel_dimension))\n",
    "\n",
    "#         # 第二全连接层\n",
    "#         model.add(Dense(256, kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"relu\"))\n",
    "#         model.add(Dropout(0.5))\n",
    "#         # model.add(BatchNormalization(axis=channel_dimension))\n",
    "\n",
    "#         # 第三全连接层\n",
    "#         model.add(Dense(classes, kernel_regularizer=l2(reg)))\n",
    "#         model.add(Activation(\"softmax\"))\n",
    "\n",
    "#         return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MiniVGG13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 12, 12, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 6, 6, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1024)              4719616   \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,487,367\n",
      "Trainable params: 9,485,447\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# ### Source: https://www.kaggle.com/code/gxy19980906/320203298minivgg11\n",
    "# # 测试MiniVGG13类实例化并输出MiniVGG13模型的概要信息\n",
    "# if __name__ == \"__main__\":\n",
    "#     model = MiniVGG11Net.build(width=48, height=48, channel=1, classes=7, reg=0.0002)\n",
    "#     print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty sequential model\n",
    "# model = Sequential(name=\"MiniVGG13\")\n",
    "\n",
    "# reg = 0.0002\n",
    "# shape = (48, 48, 1)\n",
    "# channel_dimension = -1\n",
    "\n",
    "# if backend.image_data_format() == \"channels_first\":\n",
    "#     shape = (1, 48, 48)\n",
    "#     channel_dimension = 1\n",
    "\n",
    "# model.add(Conv2D(64, (3, 3), input_shape=shape, padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=channel_dimension))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=channel_dimension))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=channel_dimension))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Conv2D(512, (3, 3), padding=\"same\", kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(BatchNormalization(axis=channel_dimension))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "#  # 第一全连接层\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(1024, kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # model.add(BatchNormalization(axis=channel_dimension))\n",
    "\n",
    "# # 第二全连接层\n",
    "# model.add(Dense(256, kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"relu\"))\n",
    "# model.add(Dropout(0.5))\n",
    "# # model.add(BatchNormalization(axis=channel_dimension))\n",
    "\n",
    "# # 第三全连接层\n",
    "# model.add(Dense(face_classes, kernel_regularizer=l2(reg)))\n",
    "# model.add(Activation(\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 244 images belonging to 16 classes.\n",
      "Found 244 images belonging to 16 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'face1': 0,\n",
       " 'face10': 1,\n",
       " 'face11': 2,\n",
       " 'face12': 3,\n",
       " 'face13': 4,\n",
       " 'face14': 5,\n",
       " 'face15': 6,\n",
       " 'face16': 7,\n",
       " 'face2': 8,\n",
       " 'face3': 9,\n",
       " 'face4': 10,\n",
       " 'face5': 11,\n",
       " 'face6': 12,\n",
       " 'face7': 13,\n",
       " 'face8': 14,\n",
       " 'face9': 15}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####### IMAGE PRE-PROCESSING for TRAINING and TESTING data\n",
    " \n",
    "# Specifying the folder where images are present\n",
    "TrainingImagePath='resources/Face Images/Final Training Images'\n",
    " \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# Understand more about ImageDataGenerator at below link\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    " \n",
    "# Defining pre-processing transformations on raw images of training data\n",
    "# These hyper parameters helps to generate slightly twisted versions\n",
    "# of the original image, which leads to a better model, since it learns\n",
    "# on the good and bad mix of images\n",
    "train_datagen = ImageDataGenerator(\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Defining pre-processing transformations on raw images of testing data\n",
    "# No transformations are done on the testing images\n",
    "test_datagen = ImageDataGenerator()\n",
    " \n",
    "# Generating the Training Data\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(48, 48),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    " \n",
    " \n",
    "# Generating the Testing Data\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        TrainingImagePath,\n",
    "        target_size=(48, 48),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    " \n",
    "# Printing class labels for each face\n",
    "test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####### IMAGE PRE-PROCESSING for TRAINING and TESTING data\n",
    " \n",
    "# # Specifying the folder where images are present\n",
    "# TrainingImagePath='resources/Face Images/Final Training Images'\n",
    " \n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "# # Understand more about ImageDataGenerator at below link\n",
    "# # https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    " \n",
    "# # Defining pre-processing transformations on raw images of training data\n",
    "# # These hyper parameters helps to generate slightly twisted versions\n",
    "# # of the original image, which leads to a better model, since it learns\n",
    "# # on the good and bad mix of images\n",
    "# train_datagen = ImageDataGenerator(\n",
    "#         shear_range=0.1,\n",
    "#         zoom_range=0.1,\n",
    "#         horizontal_flip=True)\n",
    " \n",
    "# # Defining pre-processing transformations on raw images of testing data\n",
    "# # No transformations are done on the testing images\n",
    "# test_datagen = ImageDataGenerator()\n",
    " \n",
    "# # Generating the Training Data\n",
    "# training_set = train_datagen.flow_from_directory(\n",
    "#         TrainingImagePath,\n",
    "#         target_size=(64, 64),\n",
    "#         batch_size=32,\n",
    "#         class_mode='categorical')\n",
    " \n",
    " \n",
    "# # Generating the Testing Data\n",
    "# test_set = test_datagen.flow_from_directory(\n",
    "#         TrainingImagePath,\n",
    "#         target_size=(64, 64),\n",
    "#         batch_size=32,\n",
    "#         class_mode='categorical')\n",
    " \n",
    "# # Printing class labels for each face\n",
    "# test_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping of Face and its ID {0: 'face1', 1: 'face10', 2: 'face11', 3: 'face12', 4: 'face13', 5: 'face14', 6: 'face15', 7: 'face16', 8: 'face2', 9: 'face3', 10: 'face4', 11: 'face5', 12: 'face6', 13: 'face7', 14: 'face8', 15: 'face9'}\n",
      "\n",
      " The Number of output neurons:  16\n"
     ]
    }
   ],
   "source": [
    "########### Creating lookup table for all faces\n",
    "# class_indices have the numeric tag for each face\n",
    "TrainClasses=training_set.class_indices\n",
    " \n",
    "# Storing the face and the numeric tag for future reference\n",
    "ResultMap={}\n",
    "for faceValue,faceName in zip(TrainClasses.values(),TrainClasses.keys()):\n",
    "    ResultMap[faceValue]=faceName\n",
    " \n",
    "# Saving the face map for future reference\n",
    "import pickle\n",
    "with open(\"ResultsMap.pkl\", 'wb') as fileWriteStream:\n",
    "    pickle.dump(ResultMap, fileWriteStream)\n",
    " \n",
    "# The model will give answer as a numeric tag\n",
    "# This mapping will help to get the corresponding face name for it\n",
    "print(\"Mapping of Face and its ID\",ResultMap)\n",
    " \n",
    "# The number of neurons for the output layer is equal to the number of faces\n",
    "OutputNeurons=len(ResultMap)\n",
    "print('\\n The Number of output neurons: ', OutputNeurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  SOURCE: https://thinkingneuron.com/face-recognition-using-deep-learning-cnn-in-python/\n",
    "# Create and empty sequential model, initializing the Convolution Neural Network\n",
    "face_model = Sequential()\n",
    "\n",
    "## STEP--1 Convolution\n",
    "# Adding the first layer of CNN\n",
    "# we are using the format (48,48,1) because we are using TensorFlow backend\n",
    "# It means 1 matrix of size (48X48) pixels representing grayscale components of pixels\n",
    "face_model.add(Convolution2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(48,48,3), activation='relu'))\n",
    "\n",
    "# STEP--2 MAX Pooling\n",
    "face_model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "## ADDITIONAL LAYER of CONVOLUTION for better accuracy\n",
    "face_model.add(Convolution2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "face_model.add(MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "# STEP--3 FLattening\n",
    "face_model.add(Flatten())\n",
    "\n",
    "# STEP--4 Fully Connected Neural Network\n",
    "face_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "face_model.add(Dense(OutputNeurons, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# faceifier.compile(loss='binary_crossentropy', \n",
    "#                    optimizer='adam', \n",
    "#                    metrics=['accuracy'])\n",
    "face_model.compile(loss='categorical_crossentropy', \n",
    "                   optimizer = 'adam', \n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# Measuring the time taken by the model to train\n",
    "StartTime=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 296, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 48, 48, 3), found shape=(None, 2304)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f_/gtsdwfmx7s384m5wp2qkks000000gn/T/ipykernel_1865/4080250097.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     validation_steps=10)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mEndTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2616\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m             \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2619\u001b[0m         )\n\u001b[1;32m   2620\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 296, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 48, 48, 3), found shape=(None, 2304)\n"
     ]
    }
   ],
   "source": [
    "# Starting the model training\n",
    "face_model.fit_generator(\n",
    "                    X_train,\n",
    "#                     training_set,\n",
    "                    steps_per_epoch=3,\n",
    "                    epochs=10,\n",
    "                    validation_data=test_set,\n",
    "                    validation_steps=10)\n",
    " \n",
    "EndTime=time.time()\n",
    "print(\"###### Total Time Taken: \", round((EndTime-StartTime)/60), 'Minutes ######')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create an empty sequential model\n",
    "# model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add the first layer where the input dimensions are the 2304 pixel values\n",
    "# # We can also choose our activation function. `relu` is a common\n",
    "# model.add(tf.keras.layers.Dense(units=349, input_dim=2304, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add a second hidden layer\n",
    "# model.add(tf.keras.layers.Dense(units=865, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add a third hidden layer\n",
    "# model.add(tf.keras.layers.Dense(units=337, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add our final output layer where the number of nodes \n",
    "# # corresponds to the number of y labels\n",
    "# model.add(tf.keras.layers.Dense(face_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MiniVGG13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_21 (Conv2D)          (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " activation_26 (Activation)  (None, 48, 48, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 48, 48, 64)       256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 24, 24, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 24, 24, 128)       0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 24, 24, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 12, 12, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 12, 12, 256)       0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 12, 12, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 6, 6, 256)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 6, 6, 512)         0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 6, 6, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 3, 3, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1024)              4719616   \n",
      "                                                                 \n",
      " activation_32 (Activation)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               262400    \n",
      "                                                                 \n",
      " activation_33 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 7)                 1799      \n",
      "                                                                 \n",
      " activation_34 (Activation)  (None, 7)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,487,367\n",
      "Trainable params: 9,485,447\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can summarize our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile and Train our Model\n",
    "\n",
    "Now that we have our model architecture defined, we must compile the model using a loss function and optimizer. We can also specify additional training metrics such as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = MiniVGG11Net.build(width=48,height=48,channel=1,classes=NUM_CLASSES)\n",
    "\n",
    "# model.compile(loss=\"categorical_crossentropy\",\n",
    "#               optimizer='adam',\n",
    "#               metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_path = os.path.sep.join([OUTPUT_PATH, \"{}.png\".format(os.getpid())])\n",
    "# json_path = os.path.sep.join([OUTPUT_PATH,\"MiniVGG11.json\"])\n",
    "# callbacks = [TrainingMonitor(fig_path=fig_path)]\n",
    "# model.fit_generator(train_gen.generator(),\n",
    "#                     steps_per_epoch=train_gen.numImages//BATCH_SIZE,\n",
    "#                     validation_data=val_gen.generator(),\n",
    "#                     validation_steps=val_gen.numImages // BATCH_SIZE,\n",
    "#                     epochs=50,\n",
    "#                     max_queue_size=BATCH_SIZE*2,\n",
    "#                     callbacks=callbacks,\n",
    "#                     verbose=1)\n",
    "# print(\"[信息] 保存模型...\")\n",
    "# model.save(MODEL_FILE,overwrite=True)\n",
    "# train_gen.close()\n",
    "# val_gen.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "model.compile(optimizer='adam',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 48, 48, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 48, 48, 1), dtype=tf.float32, name='conv2d_21_input'), name='conv2d_21_input', description=\"created by layer 'conv2d_21_input'\"), but it was called on an input with incompatible shape (None, 48).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 251, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer 'MiniVGG13' (type Sequential).\n    \n    Input 0 of layer \"conv2d_21\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 48)\n    \n    Call arguments received by layer 'MiniVGG13' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 48), dtype=int64)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f_/gtsdwfmx7s384m5wp2qkks000000gn/T/ipykernel_1011/2755797279.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0marr_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#     verbose=2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/terryschoch/opt/anaconda3/envs/PythonData/lib/python3.7/site-packages/keras/engine/input_spec.py\", line 251, in assert_input_compatibility\n        f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer 'MiniVGG13' (type Sequential).\n    \n    Input 0 of layer \"conv2d_21\" is incompatible with the layer: expected min_ndim=4, found ndim=2. Full shape received: (None, 48)\n    \n    Call arguments received by layer 'MiniVGG13' (type Sequential):\n      • inputs=tf.Tensor(shape=(None, 48), dtype=int64)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"mnist_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "We use our testing data to validate our model. This is how we determine the validity of our model (i.e. the ability to predict new and previously unseen data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using the training data \n",
    "model_loss, model_accuracy = model.evaluate(X_test, y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "We can use our trained model to make predictions using `model.predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just one data point to test with\n",
    "test = np.expand_dims(X_train[0], axis=0)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test)\n",
    "print('Predicted:', predictions)\n",
    "\n",
    "test_img = X_train[0].reshape(48, 48)\n",
    "plt.imshow(test_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
